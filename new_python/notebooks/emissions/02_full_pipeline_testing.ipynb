{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions 02: Full Pipeline Testing\n",
    "\n",
    "**Purpose**: Test complete Emissions pipeline (Bronze → Transform → Gold)\n",
    "\n",
    "**Outputs**:\n",
    "- primes_emises_{vision}_pol_garp (by guarantee)\n",
    "- primes_emises_{vision}_pol (aggregated by policy)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /workspace/new_python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/18 21:50:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Spark 3.4.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# from azfr_fsspec_utils import fspath\n",
    "# import azfr_fsspec_abfs\n",
    "\n",
    "# azfr_fsspec_abfs.use()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Emissions_Pipeline_Testing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"✓ Spark {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing pipeline for vision: 202509\n"
     ]
    }
   ],
   "source": [
    "from utils.loaders.config_loader import ConfigLoader\n",
    "from utils.logger import PipelineLogger\n",
    "# CORRECTED: Proper import path\n",
    "from src.processors.emissions_processors.emissions_processor import EmissionsProcessor\n",
    "\n",
    "config = ConfigLoader(str(project_root / \"config\" / \"config.yml\"))\n",
    "logger = PipelineLogger(\"emissions_test\")\n",
    "\n",
    "VISION = \"202509\"\n",
    "print(f\"Testing pipeline for vision: {VISION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Emissions Processor (Manual Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-18 21:50:34 - emissions_test - INFO - Emissions Processor initialized\n",
      "Step 1: Reading bronze data...\n",
      "2025-12-18 21:50:34 - emissions_test - INFO - Reading One BI emissions data for vision 202509\n",
      "2025-12-18 21:50:38 - emissions_test - INFO - ✓ SUCCESS: Read 20,000 records from One BI (bronze)\n",
      "✓ Read: 20,000 rows\n",
      "\n",
      "Step 2: Transforming data...\n",
      "2025-12-18 21:50:38 - emissions_test - INFO - Starting Emissions transformations\n",
      "2025-12-18 21:50:38 - emissions_test - INFO - STEP 1: Lowercasing all columns\n",
      "2025-12-18 21:50:38 - emissions_test - INFO - STEP 2: Applying business filters\n",
      "2025-12-18 21:50:38 - emissions_test - INFO - After market filter (cd_marche='6'): 20,000 records\n",
      "2025-12-18 21:50:38 - emissions_test - INFO - After date filter (dt_cpta_cts <= 202509): 20,000 records\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - After intermediary filter (22 excluded): 20,000 records\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - ✓ SUCCESS: Filters applied: 0 records filtered out, 20,000 remaining\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - STEP 3: Assigning distribution channel (CDPOLE)\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - CDPOLE assigned: '1' (Agent) for DCAG/DCPS/DIGITAL, '3' (Courtage) for BROKDIV\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - STEP 4: Calculating EXERCICE (current/prior year split)\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - EXERCICE calculated: 'cou' (current) if nu_ex_ratt_cts >= year, else 'ant' (prior)\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - STEP 5: Extracting guarantee code (CGARP)\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - CGARP extracted from cd_gar_prospctiv (chars 3-5)\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - STEP 6: Transforming columns and calculating premiums\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - Premiums calculated: primes_x (all years), primes_n (current year only)\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - STEP 7: Enriching with segmentation\n",
      "2025-12-18 21:50:39 - emissions_test - INFO - Segmentation enrichment successful\n",
      "2025-12-18 21:50:41 - emissions_test - INFO - After cmarch='6' filter: 20,000 records\n",
      "2025-12-18 21:50:41 - emissions_test - INFO - STEP 8: Creating aggregated outputs\n",
      "2025-12-18 21:50:41 - emissions_test - INFO - POL_GARP aggregation: 20,000 records\n",
      "2025-12-18 21:50:42 - emissions_test - INFO - POL aggregation: 20,000 records\n",
      "2025-12-18 21:50:42 - emissions_test - INFO - ✓ SUCCESS: Emissions transformations completed\n",
      "✓ POL_GARP (by guarantee): 20,000 rows\n",
      "✓ POL (aggregated): 20,000 rows\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    emissions_processor = EmissionsProcessor(spark, config, logger)\n",
    "    \n",
    "    # CORRECTED: Use read() + transform() instead of run()\n",
    "    # run() writes directly to gold and returns None\n",
    "    \n",
    "    # Step 1: Read bronze data\n",
    "    print(\"Step 1: Reading bronze data...\")\n",
    "    df = emissions_processor.read(VISION)\n",
    "    print(f\"✓ Read: {df.count():,} rows\")\n",
    "    \n",
    "    # Step 2: Transform (returns tuple of 2 DataFrames)\n",
    "    print(\"\\nStep 2: Transforming data...\")\n",
    "    df_pol_garp, df_pol = emissions_processor.transform(df, VISION)\n",
    "    \n",
    "    print(f\"✓ POL_GARP (by guarantee): {df_pol_garp.count():,} rows\")\n",
    "    print(f\"✓ POL (aggregated): {df_pol.count():,} rows\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    df_pol_garp = df_pol = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Output Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POL_GARP Schema:\n",
      "  Columns: ['vision', 'dircom', 'cdpole', 'nopol', 'cdprod', 'noint', 'cgarp', 'cmarch', 'cseg', 'cssseg', 'cd_cat_min', 'primes_x', 'primes_n', 'mtcom_x']\n",
      "\n",
      "Expected: vision, dircom, cdpole, nopol, cdprod, noint, cgarp, cmarch, cseg, cssseg, cd_cat_min, primes_x, primes_n, mtcom_x\n"
     ]
    }
   ],
   "source": [
    "if df_pol_garp is not None:\n",
    "    print(\"POL_GARP Schema:\")\n",
    "    print(f\"  Columns: {df_pol_garp.columns}\")\n",
    "    print(\"\\nExpected: vision, dircom, cdpole, nopol, cdprod, noint, cgarp, cmarch, cseg, cssseg, cd_cat_min, primes_x, primes_n, mtcom_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POL Schema:\n",
      "  Columns: ['vision', 'dircom', 'nopol', 'noint', 'cdpole', 'cdprod', 'cmarch', 'cseg', 'cssseg', 'primes_x', 'primes_n', 'mtcom_x']\n",
      "\n",
      "Expected: vision, dircom, cdpole, nopol, cdprod, noint, cmarch, cseg, cssseg, primes_x, primes_n, mtcom_x\n"
     ]
    }
   ],
   "source": [
    "if df_pol is not None:\n",
    "    print(\"POL Schema:\")\n",
    "    print(f\"  Columns: {df_pol.columns}\")\n",
    "    print(\"\\nExpected: vision, dircom, cdpole, nopol, cdprod, noint, cmarch, cseg, cssseg, primes_x, primes_n, mtcom_x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POL_GARP output (by guarantee):\n",
      "+-----------+------+-----+--------+--------+\n",
      "|      nopol|cdprod|cgarp|primes_x|primes_n|\n",
      "+-----------+------+-----+--------+--------+\n",
      "|POL00009453| 01030|310YY|15010.72|15010.72|\n",
      "|POL00009911| 01056|300YY|15103.07|     0.0|\n",
      "|POL00011327| 01082|260YY|35916.96|35916.96|\n",
      "|POL00011176| 01141|310YY| 25051.7|     0.0|\n",
      "|POL00003479| 01081|240YY|14007.18|14007.18|\n",
      "+-----------+------+-----+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "POL output (aggregated by policy):\n",
      "+-----------+------+--------+--------+\n",
      "|      nopol|cdprod|primes_x|primes_n|\n",
      "+-----------+------+--------+--------+\n",
      "|POL00001661| 01109|30698.44|     0.0|\n",
      "|POL00000926| 01090|24266.67|24266.67|\n",
      "|POL00011082| 01085|20295.41|     0.0|\n",
      "|POL00013129| 01080|29919.31|29919.31|\n",
      "|POL00007736| 01098|43718.11|43718.11|\n",
      "+-----------+------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if df_pol_garp is not None:\n",
    "    print(\"POL_GARP output (by guarantee):\")\n",
    "    # CORRECTED: Use actual column names (primes_x, primes_n, cgarp)\n",
    "    df_pol_garp.select('nopol', 'cdprod', 'cgarp', 'primes_x', 'primes_n').show(5)\n",
    "    \n",
    "    print(\"\\nPOL output (aggregated by policy):\")\n",
    "    # CORRECTED: Use actual column names\n",
    "    df_pol.select('nopol', 'cdprod', 'primes_x', 'primes_n').show(5)\n",
    "else:\n",
    "    print(\"⚠ No data to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validate Aggregation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: POL should be aggregation of POL_GARP\n",
      "\n",
      "Sample policy: POL00010331\n",
      "\n",
      "POL_GARP (by guarantee):\n",
      "+-----+--------+\n",
      "|cgarp|primes_x|\n",
      "+-----+--------+\n",
      "|220YY|15493.65|\n",
      "|240YY|29407.58|\n",
      "+-----+--------+\n",
      "\n",
      "POL (aggregated):\n",
      "+--------+\n",
      "|primes_x|\n",
      "+--------+\n",
      "|15493.65|\n",
      "|29407.58|\n",
      "+--------+\n",
      "\n",
      "✓ Validation complete\n"
     ]
    }
   ],
   "source": [
    "if df_pol_garp is not None and df_pol is not None:\n",
    "    # Verify POL is aggregation of POL_GARP\n",
    "    print(\"Validation: POL should be aggregation of POL_GARP\")\n",
    "    \n",
    "    # Pick one policy\n",
    "    sample_nopol = df_pol.select('nopol').first()['nopol']\n",
    "    \n",
    "    print(f\"\\nSample policy: {sample_nopol}\")\n",
    "    \n",
    "    # POL_GARP for this policy (multiple guarantees)\n",
    "    garp_data = df_pol_garp.filter(df_pol_garp.nopol == sample_nopol).select('cgarp', 'primes_x')\n",
    "    print(\"\\nPOL_GARP (by guarantee):\")\n",
    "    garp_data.show()\n",
    "    \n",
    "    # POL for this policy (aggregated)\n",
    "    pol_data = df_pol.filter(df_pol.nopol == sample_nopol).select('primes_x')\n",
    "    print(\"POL (aggregated):\")\n",
    "    pol_data.show()\n",
    "    \n",
    "    print(\"✓ Validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optional: Write to Gold (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to write outputs manually\n",
    "# if df_pol_garp is not None and df_pol is not None:\n",
    "#     emissions_processor.write((df_pol_garp, df_pol), VISION)\n",
    "#     print(\"✓ Data written to gold layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EMISSIONS PIPELINE TESTING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nVision: {VISION}\")\n",
    "print(f\"POL_GARP: {'✓' if df_pol_garp is not None else '✗'}\")\n",
    "print(f\"POL:      {'✓' if df_pol is not None else '✗'}\")\n",
    "print(\"\\nKey learnings:\")\n",
    "print(\"  1. Use read() + transform() for testing (run() writes directly)\")\n",
    "print(\"  2. transform() returns tuple of (df_pol_garp, df_pol)\")\n",
    "print(\"  3. Column names: primes_x, primes_n, cgarp, mtcom_x\")\n",
    "print(\"\\n→ Run production: python main.py --vision 202509 --component emissions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
