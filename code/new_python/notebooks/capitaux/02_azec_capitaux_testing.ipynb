{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitaux 02: AZEC Capitaux Processor Testing\n",
    "\n",
    "**Purpose**: Test AZEC capital extraction from CAPITXCU and INCENDCU data\n",
    "\n",
    "**Tests**:\n",
    "1. Read CAPITXCU and INCENDCU bronze data\n",
    "2. Extract capital columns (capx_100, capx_cua, smp_sre)\n",
    "3. Aggregate PE/RD from INCENDCU (mt_baspe, mt_basdi)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /workspace/new_python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/17 20:15:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Spark 3.4.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# from azfr_fsspec_utils import fspath\n",
    "# import azfr_fsspec_abfs\n",
    "\n",
    "# azfr_fsspec_abfs.use()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Capitaux_AZEC_Testing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"✓ Spark {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision: 202509\n"
     ]
    }
   ],
   "source": [
    "from utils.loaders.config_loader import ConfigLoader\n",
    "from src.reader import BronzeReader\n",
    "\n",
    "config = ConfigLoader(str(project_root / \"config\" / \"config.yml\"))\n",
    "bronze_reader = BronzeReader(\n",
    "    spark, config,\n",
    "    str(project_root / \"config\" / \"reading_config.json\")\n",
    ")\n",
    "\n",
    "VISION = \"202509\"\n",
    "print(f\"Vision: {VISION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read CAPITXCU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CAPITXCU: 1,600 rows\n",
      "  Columns: ['police', 'produit', 'smp_sre', 'brch_rea', 'capx_100', 'capx_cua', '_source_file']\n",
      "+---------+-------+-------+--------+---------+---------+--------------------+\n",
      "|   police|produit|smp_sre|brch_rea| capx_100| capx_cua|        _source_file|\n",
      "+---------+-------+-------+--------+---------+---------+--------------------+\n",
      "|AZ0000465|    A00|    LCI|     ID0|337013.87| 59449.65|file:///workspace...|\n",
      "|AZ0000136|    A00|    SMP|     ID0|458517.31| 90660.08|file:///workspace...|\n",
      "|AZ0000253|    A00|    SMP|     ID0|257900.83|289002.02|file:///workspace...|\n",
      "+---------+-------+-------+--------+---------+---------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_capitxcu = bronze_reader.read_file_group('capitxcu_azec', VISION)\n",
    "    print(f\"✓ CAPITXCU: {df_capitxcu.count():,} rows\")\n",
    "    print(f\"  Columns: {df_capitxcu.columns}\")\n",
    "    df_capitxcu.show(3)\n",
    "except Exception as e:\n",
    "    print(f\"⚠ CAPITXCU not available: {e}\")\n",
    "    df_capitxcu = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read INCENDCU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ INCENDCU: 600 rows\n",
      "  Columns: ['police', 'produit', 'cod_naf', 'cod_tre', 'mt_baspe', 'mt_basdi', '_source_file']\n",
      "+---------+-------+-------+-------+--------+--------+--------------------+\n",
      "|   police|produit|cod_naf|cod_tre|mt_baspe|mt_basdi|        _source_file|\n",
      "+---------+-------+-------+-------+--------+--------+--------------------+\n",
      "|AZ0000784|    A00|  4120A|    T01| 10000.0| 20000.0|file:///workspace...|\n",
      "|AZ0000443|    A00|  4120A|    T01| 10000.0| 20000.0|file:///workspace...|\n",
      "|AZ0000482|    A00|  4120A|    T01| 10000.0| 20000.0|file:///workspace...|\n",
      "+---------+-------+-------+-------+--------+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_incendcu = bronze_reader.read_file_group('incendcu_azec', VISION)\n",
    "    print(f\"✓ INCENDCU: {df_incendcu.count():,} rows\")\n",
    "    print(f\"  Columns: {df_incendcu.columns}\")\n",
    "    df_incendcu.show(3)\n",
    "except Exception as e:\n",
    "    print(f\"⚠ INCENDCU not available: {e}\")\n",
    "    df_incendcu = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Capital Aggregation (INCENDCU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Aggregated PE/RD by policy: 440 policies\n",
      "+---------+-------+--------------+------------------+\n",
      "|   police|produit|perte_exp_azec|risque_direct_azec|\n",
      "+---------+-------+--------------+------------------+\n",
      "|AZ0000527|    A00|       20000.0|           40000.0|\n",
      "|AZ0000772|    A00|       10000.0|           20000.0|\n",
      "|AZ0000761|    A00|       20000.0|           40000.0|\n",
      "|AZ0000028|    A00|       10000.0|           20000.0|\n",
      "|AZ0000220|    A00|       10000.0|           20000.0|\n",
      "+---------+-------+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "if df_incendcu is not None:\n",
    "    # Aggregate PE and RD by policy\n",
    "    df_pe_rd = df_incendcu.groupBy('police', 'produit').agg(\n",
    "        spark_sum('mt_baspe').alias('perte_exp_azec'),\n",
    "        spark_sum('mt_basdi').alias('risque_direct_azec')\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Aggregated PE/RD by policy: {df_pe_rd.count():,} policies\")\n",
    "    df_pe_rd.show(5)\n",
    "else:\n",
    "    print(\"⚠ Skipping aggregation - no INCENDCU data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AZEC CAPITAUX TESTING COMPLETE\n",
      "============================================================\n",
      "CAPITXCU: Available\n",
      "INCENDCU: Available\n",
      "\n",
      "→ Next: Notebook 03 - Consolidation\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"AZEC CAPITAUX TESTING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"CAPITXCU: {'Available' if df_capitxcu is not None else 'Not available'}\")\n",
    "print(f\"INCENDCU: {'Available' if df_incendcu is not None else 'Not available'}\")\n",
    "print(\"\\n→ Next: Notebook 03 - Consolidation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
