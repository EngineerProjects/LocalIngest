{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Capitaux 03: Full Pipeline Testing\n",
                "\n",
                "**Purpose**: Test complete Capitaux pipeline (AZ + AZEC → Silver)\n",
                "\n",
                "**Tests**:\n",
                "1. Run AZCapitauxProcessor\n",
                "2. Run AZECCapitauxProcessor  \n",
                "3. Verify output datasets\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Project root: /workspace/new_python\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "project_root = Path.cwd().parent.parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "print(f\"Project root: {project_root}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
                        "25/12/17 20:59:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Spark 3.4.4\n"
                    ]
                }
            ],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "# from azfr_fsspec_utils import fspath\n",
                "# import azfr_fsspec_abfs\n",
                "\n",
                "# azfr_fsspec_abfs.use()\n",
                "\n",
                "spark = SparkSession.builder \\\n",
                "    .appName(\"Capitaux_Pipeline_Testing\") \\\n",
                "    .getOrCreate()\n",
                "\n",
                "print(f\"✓ Spark {spark.version}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Initialize Processors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing pipeline for vision: 202509\n"
                    ]
                }
            ],
            "source": [
                "from utils.loaders.config_loader import ConfigLoader\n",
                "from utils.logger import PipelineLogger\n",
                "from src.processors.capitaux_processors.az_capitaux_processor import AZCapitauxProcessor\n",
                "from src.processors.capitaux_processors.azec_capitaux_processor import AZECCapitauxProcessor\n",
                "\n",
                "config = ConfigLoader(str(project_root / \"config\" / \"config.yml\"))\n",
                "logger = PipelineLogger(\"capitaux_test\")\n",
                "\n",
                "VISION = \"202509\"\n",
                "print(f\"Testing pipeline for vision: {VISION}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Run AZ Capitaux Processor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2025-12-17 20:59:35 - capitaux_test - INFO - AZ Capitaux Processor initialized\n",
                        "Step 1: Reading AZ bronze data...\n",
                        "2025-12-17 20:59:35 - capitaux_test - INFO - Reading AZ capital data for vision 202509\n",
                        "2025-12-17 20:59:40 - capitaux_test - INFO - ✓ SUCCESS: Read 30,000 records from bronze (AZ)\n",
                        "✓ Read: 30,000 rows\n",
                        "\n",
                        "Step 2: Transforming AZ data...\n",
                        "2025-12-17 20:59:41 - capitaux_test - INFO - Starting AZ capital transformations\n",
                        "2025-12-17 20:59:41 - capitaux_test - INFO - STEP 1: Applying business filters\n",
                        "2025-12-17 20:59:41 - capitaux_test - INFO - Business filters applied successfully (7 filters)\n",
                        "2025-12-17 20:59:42 - capitaux_test - INFO - After filters: 30,000 records\n",
                        "2025-12-17 20:59:42 - capitaux_test - INFO - STEP 2: Applying column configuration\n",
                        "2025-12-17 20:59:42 - capitaux_test - INFO - STEP 3: Extracting capitals WITH indexation\n",
                        "2025-12-17 20:59:42 - capitaux_test - INFO - Starting capital indexation for 14 columns\n",
                        "2025-12-17 20:59:47 - capitaux_test - INFO - ✓ SUCCESS: Capital indexation completed for 14 columns\n",
                        "2025-12-17 20:59:49 - capitaux_test - INFO - Indexed capitals extracted: smp_100_ind, lci_100_ind, perte_exp_100_ind, etc.\n",
                        "2025-12-17 20:59:49 - capitaux_test - INFO - STEP 4: Extracting capitals WITHOUT indexation\n",
                        "2025-12-17 20:59:50 - capitaux_test - INFO - Non-indexed capitals extracted: smp_100, lci_100, perte_exp_100, etc.\n",
                        "2025-12-17 20:59:50 - capitaux_test - INFO - STEP 5: Normalizing capitals to 100%\n",
                        "2025-12-17 20:59:52 - capitaux_test - INFO - Capitals normalized to 100% technical basis\n",
                        "2025-12-17 20:59:52 - capitaux_test - INFO - STEP 6: Applying business rules\n",
                        "2025-12-17 20:59:53 - capitaux_test - INFO - Business rules applied: SMP completion, RC limits\n",
                        "2025-12-17 20:59:53 - capitaux_test - INFO - STEP 7: Enriching with segmentation\n",
                        "2025-12-17 20:59:53 - capitaux_test - INFO - Segmentation enrichment successful\n",
                        "2025-12-17 20:59:53 - capitaux_test - INFO - ✓ SUCCESS: AZ capital transformations completed\n",
                        "✓ AZ Capitaux: 30,000 rows\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "25/12/17 20:59:56 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-----------+------------------+------------------+\n",
                        "|      nopol|       smp_100_ind|       lci_100_ind|\n",
                        "+-----------+------------------+------------------+\n",
                        "|POL00000001| 371783.2128600712| 416142.4045579633|\n",
                        "|POL00000002|421077.06401883403|               0.0|\n",
                        "|POL00000003|25808.016231812424|465914.22257479606|\n",
                        "|POL00000004|486766.65877089376|  424164.860278312|\n",
                        "|POL00000005| 426367.5303140222| 263618.7169654887|\n",
                        "+-----------+------------------+------------------+\n",
                        "only showing top 5 rows\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "try:\n",
                "    az_processor = AZCapitauxProcessor(spark, config, logger)\n",
                "    \n",
                "    # CORRECTED: Use read() + transform() pattern\n",
                "    print(\"Step 1: Reading AZ bronze data...\")\n",
                "    df_az = az_processor.read(VISION)\n",
                "    print(f\"✓ Read: {df_az.count():,} rows\")\n",
                "    \n",
                "    print(\"\\nStep 2: Transforming AZ data...\")\n",
                "    df_az_transformed = az_processor.transform(df_az, VISION)\n",
                "    print(f\"✓ AZ Capitaux: {df_az_transformed.count():,} rows\")\n",
                "    \n",
                "    # Show sample\n",
                "    df_az_transformed.select('nopol', 'smp_100_ind', 'lci_100_ind').show(5)\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"✗ AZ Processor error: {e}\")\n",
                "    import traceback\n",
                "    traceback.print_exc()\n",
                "    df_az_transformed = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run AZEC Capitaux Processor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2025-12-17 20:59:58 - capitaux_test - INFO - AZEC Capitaux Processor initialized\n",
                        "Step 1: Reading AZEC bronze data...\n",
                        "2025-12-17 20:59:58 - capitaux_test - INFO - Reading AZEC capital data for vision 202509\n",
                        "2025-12-17 20:59:59 - capitaux_test - INFO - ✓ SUCCESS: Read 1,600 records from CAPITXCU\n",
                        "✓ Read CAPITXCU: 1,600 rows\n",
                        "\n",
                        "Step 2: Transforming AZEC data...\n",
                        "2025-12-17 20:59:59 - capitaux_test - INFO - Starting AZEC capital transformations\n",
                        "2025-12-17 20:59:59 - capitaux_test - INFO - STEP 1: Processing CAPITXCU (SMP/LCI by branch)\n",
                        "2025-12-17 20:59:59 - capitaux_test - INFO - STEP 2: Reading and aggregating INCENDCU (PE/RD)\n",
                        "2025-12-17 20:59:59 - capitaux_test - INFO - STEP 3: Joining PE/RD data\n",
                        "2025-12-17 20:59:59 - capitaux_test - INFO - STEP 4: Enriching with segmentation\n",
                        "2025-12-17 20:59:59 - capitaux_test - INFO - Segmentation enrichment successful\n",
                        "2025-12-17 20:59:59 - capitaux_test - INFO - STEP 5: Filtering construction market (CMARCH=6)\n",
                        "2025-12-17 21:00:00 - capitaux_test - INFO - After CMARCH=6 filter: 1,598 rows\n",
                        "2025-12-17 21:00:00 - capitaux_test - INFO - ✓ SUCCESS: AZEC capital transformations completed\n",
                        "✓ AZEC Capitaux: 1,598 rows\n",
                        "+---------+------+-----------+-----------+\n",
                        "|    nopol|cdprod|smp_100_ind|lci_100_ind|\n",
                        "+---------+------+-----------+-----------+\n",
                        "|AZ0000155|  0040|        0.0|  348328.44|\n",
                        "|AZ0000333|  0060|    42820.7|        0.0|\n",
                        "|AZ0000705|  0062|        0.0|  228292.87|\n",
                        "|AZ0000457|  0292|  484111.88|        0.0|\n",
                        "|AZ0000629|  0154|  411268.81|        0.0|\n",
                        "+---------+------+-----------+-----------+\n",
                        "only showing top 5 rows\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "try:\n",
                "    azec_processor = AZECCapitauxProcessor(spark, config, logger)\n",
                "    \n",
                "    # CORRECTED: Use read() + transform() pattern\n",
                "    print(\"Step 1: Reading AZEC bronze data...\")\n",
                "    df_azec = azec_processor.read(VISION)\n",
                "    print(f\"✓ Read CAPITXCU: {df_azec.count():,} rows\")\n",
                "    \n",
                "    print(\"\\nStep 2: Transforming AZEC data...\")\n",
                "    df_azec_transformed = azec_processor.transform(df_azec, VISION)\n",
                "    print(f\"✓ AZEC Capitaux: {df_azec_transformed.count():,} rows\")\n",
                "    \n",
                "    # Show sample\n",
                "    df_azec_transformed.select('nopol', 'cdprod', 'smp_100_ind', 'lci_100_ind').show(5)\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"⚠ AZEC Processor (expected if CAPITXCU missing): {e}\")\n",
                "    df_azec_transformed = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Verify Output Schemas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "AZ Schema:\n",
                        "  Columns: 191\n",
                        "  Capital columns: ['smp_100_ind', 'lci_100_ind', 'perte_exp_100_ind', 'risque_direct_100_ind', 'limite_rc_100_par_sin_ind']\n",
                        "\n",
                        "AZEC Schema:\n",
                        "  Columns: 20\n",
                        "  Capital columns: ['smp_pe_100', 'smp_dd_100', 'lci_pe_100', 'lci_dd_100', 'smp_100_ind']\n"
                    ]
                }
            ],
            "source": [
                "if df_az_transformed is not None:\n",
                "    print(\"AZ Schema:\")\n",
                "    print(f\"  Columns: {len(df_az_transformed.columns)}\")\n",
                "    print(f\"  Capital columns: {[c for c in df_az_transformed.columns if '100' in c][:5]}\")\n",
                "    \n",
                "if df_azec_transformed is not None:\n",
                "    print(\"\\nAZEC Schema:\")\n",
                "    print(f\"  Columns: {len(df_azec_transformed.columns)}\")\n",
                "    print(f\"  Capital columns: {[c for c in df_azec_transformed.columns if '100' in c][:5]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Optional: Write to Silver (Manual)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment to write outputs manually\n",
                "# if df_az_transformed is not None:\n",
                "#     az_processor.write(df_az_transformed, VISION)\n",
                "#     print(\"✓ AZ data written to silver\")\n",
                "# \n",
                "# if df_azec_transformed is not None:\n",
                "#     azec_processor.write(df_azec_transformed, VISION)\n",
                "#     print(\"✓ AZEC data written to silver\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "============================================================\n",
                        "CAPITAUX PIPELINE TESTING COMPLETE\n",
                        "============================================================\n",
                        "\n",
                        "Vision: 202509\n",
                        "AZ Capitaux:   ✓\n",
                        "AZEC Capitaux: ✓\n",
                        "\n",
                        "Key learnings:\n",
                        "  1. Use read() + transform() for testing (run() writes directly)\n",
                        "  2. AZ: ipf file_group (combines IPFE16 + IPFE36)\n",
                        "  3. AZEC: capitxcu_azec + incendcu_azec\n",
                        "  4. Both create indexed (_ind) and non-indexed capitals\n",
                        "\n",
                        "→ Run production: python main.py --vision 202509 --component capitaux\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"CAPITAUX PIPELINE TESTING COMPLETE\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nVision: {VISION}\")\n",
                "print(f\"AZ Capitaux:   {'✓' if df_az_transformed is not None else '✗'}\")\n",
                "print(f\"AZEC Capitaux: {'✓' if df_azec_transformed is not None else '⚠ (optional)'}\")\n",
                "\n",
                "print(\"\\nKey learnings:\")\n",
                "print(\"  1. Use read() + transform() for testing (run() writes directly)\")\n",
                "print(\"  2. AZ: ipf file_group (combines IPFE16 + IPFE36)\")\n",
                "print(\"  3. AZEC: capitxcu_azec + incendcu_azec\")\n",
                "print(\"  4. Both create indexed (_ind) and non-indexed capitals\")\n",
                "print(\"\\n→ Run production: python main.py --vision 202509 --component capitaux\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}