{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PTF_MVT 01: Bronze Reading & Filters\n",
                "\n",
                "**Purpose**: Test bronze reading and business filters\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Project root: /workspace/new_python\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "project_root = Path.cwd().parent.parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "print(f\"Project root: {project_root}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Spark 3.4.4\n"
                    ]
                }
            ],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "# from azfr_fsspec_utils import fspath\n",
                "# import azfr_fsspec_abfs\n",
                "\n",
                "# azfr_fsspec_abfs.use()\n",
                "\n",
                "spark = SparkSession.builder \\\n",
                "    .appName(\"PTF_MVT_Bronze\") \\\n",
                "    .getOrCreate()\n",
                "\n",
                "print(f\"✓ Spark {spark.version}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vision: 202509\n"
                    ]
                }
            ],
            "source": [
                "from utils.loaders.config_loader import ConfigLoader\n",
                "from utils.loaders.transformation_loader import TransformationLoader\n",
                "from src.reader import BronzeReader\n",
                "\n",
                "config = ConfigLoader(str(project_root / \"config\" / \"config.yml\"))\n",
                "bronze_reader = BronzeReader(spark, config, str(project_root / \"config\" / \"reading_config.json\"))\n",
                "loader = TransformationLoader(str(project_root / \"config\" / \"transformations\"))\n",
                "\n",
                "VISION = \"202509\"\n",
                "print(f\"Vision: {VISION}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Read Bronze Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ ipf: 30,000 rows\n",
                        "✓ IPFM99: 1,000 rows\n",
                        "✓ ird_risk_q45: 2,000 rows\n",
                        "✓ ird_risk_q46: 2,000 rows\n",
                        "✓ ird_risk_qan: 1,000 rows\n"
                    ]
                }
            ],
            "source": [
                "# ipf (Agent + Courtage)\n",
                "df_ipf = bronze_reader.read_file_group('ipf', VISION)\n",
                "print(f\"✓ ipf: {df_ipf.count():,} rows\")\n",
                "\n",
                "# IPFM99 (movements)\n",
                "df_ipfm99 = bronze_reader.read_file_group('ipfm99_az', VISION)\n",
                "print(f\"✓ IPFM99: {df_ipfm99.count():,} rows\")\n",
                "\n",
                "# IRD Risk\n",
                "for ird in ['ird_risk_q45', 'ird_risk_q46', 'ird_risk_qan']:\n",
                "    try:\n",
                "        df = bronze_reader.read_file_group(ird, VISION)\n",
                "        print(f\"✓ {ird}: {df.count():,} rows\")\n",
                "    except:\n",
                "        print(f\"⚠ {ird}: not available\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Apply Business Filters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Before filters: 30,000\n",
                        "After filters:  30,000\n",
                        "Filtered:       0 (0.0%)\n"
                    ]
                }
            ],
            "source": [
                "from utils.transformations.base.generic_transforms import apply_business_filters\n",
                "\n",
                "business_rules = loader.get_business_rules()\n",
                "az_filters = business_rules['business_filters']['az']\n",
                "\n",
                "count_before = df_ipf.count()\n",
                "df_filtered = apply_business_filters(df_ipf, az_filters)\n",
                "count_after = df_filtered.count()\n",
                "\n",
                "print(f\"Before filters: {count_before:,}\")\n",
                "print(f\"After filters:  {count_after:,}\")\n",
                "print(f\"Filtered:       {count_before - count_after:,} ({(count_before-count_after)/count_before*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================================\n",
                        "BRONZE READING & FILTERS COMPLETE\n",
                        "==================================================\n",
                        "→ Next: Notebook 02 - AZ Processor\n"
                    ]
                }
            ],
            "source": [
                "print(\"=\"*50)\n",
                "print(\"BRONZE READING & FILTERS COMPLETE\")\n",
                "print(\"=\"*50)\n",
                "spark.stop()\n",
                "print(\"→ Next: Notebook 02 - AZ Processor\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}