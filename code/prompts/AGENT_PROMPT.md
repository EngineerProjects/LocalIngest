ANALYSE COMPLÃˆTE PROJET PTF_MVT - MIGRATION SAS â†’ PYSPARK

â–ˆ CONTEXTE GÃ‰NÃ‰RAL
Migration d'un systÃ¨me de reporting d'assurance construction (Portefeuille Mouvements)
- Source : SAS Enterprise Guide (production actuelle)
- Cible : PySpark sur Azure Databricks
- PÃ©rimÃ¨tre : 3 pipelines interconnectÃ©s (AZ, AZEC, CONSOLIDATION)
- Vision exemple : 202509 (Septembre 2025)

â–ˆ ARCHITECTURE PROJET

ğŸ“‚ PYTHON : /home/amiche/Projects/LocalIngest/code/new_python/

1ï¸âƒ£ PIPELINES PRINCIPAUX (src/)
â”œâ”€â”€ ptf_mvt_run.py
â”œâ”€â”€ read.py
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ base_processor.py
â”‚   â”œâ”€â”€ ptf_mvt_processors/
â”‚   â”‚   â”œâ”€â”€ az_processor.py (~900 lignes)
â”‚   â”‚   â””â”€â”€ Pipeline IPF AZ (Assurance Construction - donnÃ©es IMS)
â”‚   â”‚   â”œâ”€â”€ azec_processor.py (~1,400 lignes)
â”‚   â”‚   â””â”€â”€ Pipeline AZEC (Assurance Construction - donnÃ©es legacy)
â”‚   â””â”€â”€ consolidation_processor.py (~1,100 lignes)
    â””â”€â”€ Consolidation AZ + AZEC + harmonisation schÃ©mas

2ï¸âƒ£ CONFIGURATIONS
â”œâ”€â”€ config/reading_config.json (file groups, schemas, dateFormats)
â”œâ”€â”€ config/schemas.py (StructType pour tous les CSV)
â”œâ”€â”€ constants.py (constantes utilisÃ©es dans les transformations)
â”œâ”€â”€ variables.py (variables utilisÃ©es dans les transformations)
â”œâ”€â”€ config/transformations/
â”‚   â”œâ”€â”€ az_transformations.json
â”‚   â”œâ”€â”€ business_rules.json
â”‚   â”œâ”€â”€ azec_transformations.json
â”‚   â””â”€â”€ consolidation_mappings.json

3ï¸âƒ£ TRANSFORMATIONS COMMUNES (utils/transformations/)
â”œâ”€â”€ enrichment/
â”‚   â”œâ”€â”€ segmentation_enrichment.py (LOB, CONSTRCU)
â”‚   â”œâ”€â”€ risk_enrichment.py (destinat, capital)
â”‚   â”œâ”€â”€ destinat_enrichment.py (destinat)
â”‚   â””â”€â”€ client_enrichment.py (naf)
â”œâ”€â”€ operations/
â”‚   â””â”€â”€ business_logic.py (business rules - mouvements, expositions, primes)
â””â”€â”€ base/
    â”œâ”€â”€ isic_codification.py
    â”œâ”€â”€ column_operations.py
    â””â”€â”€ generic_transforms.py

4ï¸âƒ£ MAIN
â”œâ”€â”€ main.py

ğŸ“‚ SAS : /home/amiche/Projects/LocalIngest/code/sas/

â”œâ”€â”€ PTF_MVTS_AZ_MACRO.sas (~400 lignes) â†’ Baseline AZ
â”œâ”€â”€ PTF_MVTS_AZEC_MACRO.sas (~490 lignes) â†’ Baseline AZEC
â”œâ”€â”€ CONSOLID_AZ_AZEC.sas (~300 lignes) â†’ Baseline CONSOLIDATION
â”œâ”€â”€ REF_segmentation_azec.sas (~345 lignes) â†’ RÃ©fÃ©rentiel segmentation
â””â”€â”€ CODIFICATION_ISIC_CONSTRUCTION.sas

â–ˆ FLUX DE DONNÃ‰ES

INPUT (Bronze Layer - CSV):
â”œâ”€â”€ AZ: ipf16.csv, ipf32.csv, ipfm99.csv (~100k lignes)
â”œâ”€â”€ AZEC: polic_cu.csv, capitxcu.csv, incendcu.csv (~2M lignes)
â””â”€â”€ REF: lob.csv, constrcu.csv, segmentation tables

PROCESSING:
1. AZ Pipeline â†’ az_ptf_YYYYMM (Silver)
2. AZEC Pipeline â†’ azec_ptf_YYYYMM (Silver)
3. CONSOLIDATION â†’ ptf_consolide_YYYYMM (Gold)

OUTPUT:
â””â”€â”€ Delta tables avec schÃ©ma harmonisÃ© unifiÃ©

â–ˆ OBJECTIFS DE L'ANALYSE

ğŸ¯ PRIORITÃ‰ 1 - CONFORMITÃ‰ MÃ‰TIER
Pour CHAQUE pipeline (AZ, AZEC, CONSOLIDATION) :
1. Mapper Ã©tapes Python â†” SAS ligne par ligne
2. Identifier Ã©carts de logique mÃ©tier (filtres, calculs, transformations)
3. Valider row counts (input â†’ output Ã  chaque Ã©tape)
4. VÃ©rifier calculs clÃ©s :
   - Mouvements : NBPTF, NBAFN, NBRES
   - Expositions : EXPO_YTD, EXPO_GLI
   - Primes : PRIMETO, PRIMES_AFN, PRIMES_RES, PRIMES_PTF

ğŸ¯ PRIORITÃ‰ 2 - COHÃ‰RENCE INTER-PIPELINES
1. Harmonisation schÃ©mas (colonnes communes AZ/AZEC)
2. Mapping colonnes lors de la consolidation
3. Gestion des duplicates et des clÃ©s (POLICE, PRODUIT, NOPOL, CDPROD)
4. RÃ©solution des conflits de nommage

ğŸ¯ PRIORITÃ‰ 3 - DONNÃ‰ES & CONFIGURATIONS
1. Formats dates (dateFormat dans reading_config.json pour ~30 file groups)
2. SchÃ©mas PySpark (SCHEMA_REGISTRY vs CSV rÃ©els)
3. Gestion NULL SAS (".", "", " ") vs Python (None)
4. Encodage (LATIN9 vs UTF-8)

ğŸ¯ PRIORITÃ‰ 4 - PERFORMANCE & QUALITÃ‰ CODE
1. Utilisation broadcast() pour rÃ©fÃ©rences
2. StratÃ©gie caching/persisting
3. Order of operations (filter â†’ join â†’ select)
4. Code duplication entre AZ/AZEC
5. Patterns communs Ã  factoriser

â–ˆ PLAN D'ANALYSE SUGGÃ‰RÃ‰

PHASE 1 - VUE D'ENSEMBLE (1-2h)
âœ“ Lire README et documentation existante
âœ“ Parcourir structure de chaque pipeline (read â†’ transform â†’ write)
âœ“ Identifier transformations communes utilisÃ©es
âœ“ CrÃ©er diagramme architecture global

PHASE 2 - AUDIT DÃ‰TAILLÃ‰ PAR PIPELINE (3-6h)
Pour AZ, AZEC, CONSOLIDATION :
âœ“ Comparer Ã©tapes Python vs SAS
âœ“ VÃ©rifier file groups utilisÃ©s
âœ“ Valider schÃ©mas et configs
âœ“ Tester sur vision 202509

PHASE 3 - PATTERNS COMMUNS (2-3h)
âœ“ Segmentation LOB (utilisÃ©e par AZ et AZEC)
âœ“ Enrichissement capitaux
âœ“ Calcul mouvements
âœ“ Indexation primes

PHASE 4 - CONSOLIDATION (2-3h)
âœ“ Harmonisation schÃ©mas AZ/AZEC
âœ“ Mapping colonnes (rename/computed)
âœ“ Gestion conflits
âœ“ Union finale

PHASE 5 - Duplication des transformations
âœ“ Duplication des transformations
âœ“ Detecter les transformations ou fonction ou operations qui font exactement les mÃªmes chose et comments les gÃ©rÃ©es, ie les supprimÃ©s, et rÃ©organiser comme il faut pour les mettres dans le bon enplacement. surtout les fichiers dans utils/transformations

â–ˆ LIVRABLES ATTENDUS

ğŸ“Š 1. RAPPORT ARCHITECTURE GLOBALE
- Diagramme flux de donnÃ©es (Mermaid)
- Tableau comparatif 3 pipelines
- Matrice dÃ©pendances (file groups Ã— processors)
- Statistiques code (LOC, complexitÃ©, coverage)

ğŸ“‹ 2. ANALYSE CONFORMITÃ‰ PAR PIPELINE
Pour chaque pipeline (AZ/AZEC/CONSOLIDATION) :
- Tableau Ã©tapes Python â†” SAS
- Score conformitÃ© (0-100%)
- Liste Ã©carts priorisÃ©s
- Recommandations corrections

ğŸ” 3. AUDIT CONFIGURATIONS
- Validation reading_config.json (29 file groups)
- Audit dateFormats (rÃ©sultats script date_format_audit.py)
- VÃ©rification schemas.py (SCHEMA_REGISTRY)
- Mapping transformations JSON

ğŸ§ª 4. PLAN VALIDATION E2E
- Detection des duplications dans les transformations pour avoir un code propre et lisible et logique.
- CritÃ¨res succÃ¨s globaux (row counts, sums, distributions)
- Tests inter-pipelines (cohÃ©rence AZ/AZEC dans consolidation)
- Commandes exÃ©cution complÃ¨te
- Comparaison SAS vs Python outputs

ğŸ“ 5. ROADMAP AMÃ‰LIORATION
- Quick wins (corrections rapides)
- Refactoring moyen terme (patterns communs)
- Optimisations performance
- Documentation manquante

â–ˆ QUESTIONS Ã€ RÃ‰SOUDRE

â“ ARCHITECTURE
- Pourquoi 2 pipelines sÃ©parÃ©s (AZ vs AZEC) au lieu d'un unifiÃ© ?
- Quelle est la logique de dispatch (IMS vs legacy) ?
- Y a-t-il des overlaps de donnÃ©es entre AZ et AZEC ?

â“ TRANSFORMATIONS
- Quelles transformations sont identiques entre AZ/AZEC ?
- OÃ¹ sont les diffÃ©rences de logique mÃ©tier ?
- Peut-on factoriser du code commun ?

â“ DONNÃ‰ES
- Tous les file groups sont-ils utilisÃ©s actuellement ?
- Quels sont les volumes rÃ©els (min/avg/max par vision) ?
- Y a-t-il des dÃ©pendances temporelles (visions antÃ©rieures) ?

â“ QUALITÃ‰
- Existe-t-il des tests unitaires ?
- Y a-t-il une validation automatique vs SAS ?
- Comment gÃ©rer les rÃ©gressions ?
- Existe-t-il des duplications dans les transformations ?
- Comment gÃ©rer les transformations qui font exactement les mÃªmes chose et comments les gÃ©rÃ©es, ie les supprimÃ©s, et rÃ©organiser comme il faut pour les mettres dans le bon enplacement. surtout les fichiers dans utils/transformations

â–ˆ CONTRAINTES & RÃˆGLES

âœ… DO:
- TOUJOURS citer sources (fichier + ligne) pour SAS ET Python
- Valider CHAQUE affirmation avec le code source
- Proposer corrections minimales (SAS-faithful)
- Documenter les Ã©carts non-rÃ©solus avec justification

âŒ DON'T:
- Ne PAS supposer sans vÃ©rifier le code
- Ne PAS optimiser prÃ©maturÃ©ment (conformitÃ© d'abord)
- Ne PAS ignorer les warnings/edge cases
- Ne PAS modifier les configs sans comprendre l'impact

Commence par crÃ©er une vue d'ensemble de l'architecture, puis analyse AZ, AZEC et CONSOLIDATION dans cet ordre.