# Guide de Conversion des Fichiers SAS T√©l√©charg√©s

## üéØ Probl√®mes √† R√©soudre

Apr√®s t√©l√©chargement depuis SAS, vous avez :
1. ‚ùå **S√©parateur `;`** au lieu de `|`
2. ‚ùå **Encodage LATIN9** avec caract√®res "bizarres" (`√©` ‚Üí `?`)
3. ‚ö†Ô∏è **Fichiers √©normes** (40M+ lignes)

---

## ‚úÖ Solution Automatique

### **Script Optimis√© pour Gros Fichiers**

```bash
cd /home/amiche/Downloads/code

# Convertir tous les CSV t√©l√©charg√©s
python workenv/fix_csv_separator.py ~/Downloads/*.csv
```

**Avantages** :
- ‚úÖ Traite fichiers ligne par ligne (streaming)
- ‚úÖ M√©moire constante (pas de crash sur 40M lignes)
- ‚úÖ G√®re automatiquement LATIN9
- ‚úÖ Affiche progression tous les 1M lignes
- ‚úÖ Remplace caract√®res invalides automatiquement

---

## üìã Proc√©dure Compl√®te

### **1. T√©l√©charger depuis SAS**

Vous avez d√©j√† fait √ßa ! ‚úì

Fichiers obtenus :
- ‚úì segmentprdt_202509.csv
- ‚úì indices.csv
- ‚úì basecli_inv.csv (40M+ lignes)
- ‚úì histo_note_risque.csv (40M+ lignes)
- ‚úì do_dest_202110.csv
- ‚úì table_segmentation_azec_mml.csv
- ‚ùå rf_fr1_prm_dtl_midcorp_m_202509.csv (One BI - indisponible)

---

### **2. Convertir les S√©parateurs**

```bash
# Tous les fichiers d'un coup
python workenv/fix_csv_separator.py ~/Downloads/*.csv

# Ou un par un si vous pr√©f√©rez
python workenv/fix_csv_separator.py ~/Downloads/segmentprdt_202509.csv
python workenv/fix_csv_separator.py ~/Downloads/basecli_inv.csv
# etc.
```

**R√©sultat attendu** :
```
üìÑ Conversion: basecli_inv.csv
   Encodage: latin-9
   ; -> |
   ‚è≥ 1,000,000 lignes (85.3 MB)
   ‚è≥ 2,000,000 lignes (170.6 MB)
   ...
   ‚è≥ 40,000,000 lignes (3418.2 MB)
   ‚úì Termin√©: 40,123,456 lignes (3432.1 MB)
```

---

### **3. Copier vers le Datalake**

```bash
# Fichiers reference
cp ~/Downloads/segmentprdt_202509.csv /workspace/datalake/bronze/ref/
cp ~/Downloads/indices.csv /workspace/datalake/bronze/ref/
cp ~/Downloads/basecli_inv.csv /workspace/datalake/bronze/ref/
cp ~/Downloads/histo_note_risque.csv /workspace/datalake/bronze/ref/
cp ~/Downloads/do_dest_202110.csv /workspace/datalake/bronze/ref/
cp ~/Downloads/table_segmentation_azec_mml.csv /workspace/datalake/bronze/ref/
```

---

### **4. G√©n√©rer le Fichier One BI Manquant**

```bash
# Utiliser le g√©n√©rateur pour cr√©er donn√©es de test
python workenv/data_generator.py

# Copier r√©sultat
cp workenv/bronze/monthly/rf_fr1_prm_dtl_midcorp_m_202509.csv \
   /workspace/datalake/bronze/2025/09/
```

---

## üîç V√©rification Encodage

### **Probl√®me : Caract√®res `?` au lieu de `√©`, `√†`, etc.**

**Cause** : √âditeur texte ouvre en UTF-8, fichier est en LATIN9

**Solution PySpark** :
```python
# Votre config reading_config.json le g√®re d√©j√† !
"read_options": {
    "encoding": "LATIN9"  # ‚úì Correct
}
```

**PySpark convertira automatiquement** :
```
LATIN9 ‚Üí UTF-8 interne
```

### **Test Rapide**

```bash
# V√©rifier que PySpark lit bien
python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('test').getOrCreate()
df = spark.read.csv(
    '/workspace/datalake/bronze/ref/segmentprdt_202509.csv',
    sep='|',
    header=True,
    encoding='LATIN9'
)
print(f'Lignes: {df.count()}')
df.show(5)
"
```

---

## ‚ö†Ô∏è Options du Script

### **Garder l'original (backup)**

```bash
python workenv/fix_csv_separator.py --keep-original ~/Downloads/fichier.csv
# Cr√©e: fichier.csv.bak
```

### **Encodage personnalis√©**

```bash
# Si encodage diff√©rent
python workenv/fix_csv_separator.py --encoding utf-8 ~/Downloads/fichier.csv
```

---

## üéØ R√©sum√©

| √âtape | Commande | Dur√©e (40M lignes) |
|-------|----------|-------------------|
| 1. T√©l√©charger SAS | Manuel | 5-10 min |
| 2. Convertir ; ‚Üí \| | `fix_csv_separator.py` | ~2-3 min |
| 3. Copier datalake | `cp` | 1 min |
| 4. Tester PySpark | Pipeline | - |

**Total : ~10-15 minutes pour pr√©parer les donn√©es** ‚úÖ
